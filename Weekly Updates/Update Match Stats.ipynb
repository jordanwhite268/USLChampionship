{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7eceeb",
   "metadata": {},
   "source": [
    "# Access Match Report webpage and read in Match Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da348198",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'possession_home' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 100\u001b[0m\n\u001b[0;32m     84\u001b[0m     offsides_away \u001b[38;5;241m=\u001b[39m stat_values[\u001b[38;5;241m14\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame to store the match stats\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     match_stats \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_id\u001b[39m\u001b[38;5;124m'\u001b[39m: match_id,\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_manager_first\u001b[39m\u001b[38;5;124m'\u001b[39m: home_manager_first,\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_manager_last\u001b[39m\u001b[38;5;124m'\u001b[39m: home_manager_last,\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_manager_first\u001b[39m\u001b[38;5;124m'\u001b[39m: away_manager_first,\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_manager_last\u001b[39m\u001b[38;5;124m'\u001b[39m: away_manager_last,\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_captain_first\u001b[39m\u001b[38;5;124m'\u001b[39m: home_captain_first,\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_captain_last\u001b[39m\u001b[38;5;124m'\u001b[39m: home_captain_last,\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_captain_first\u001b[39m\u001b[38;5;124m'\u001b[39m: away_captain_first,\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_captain_last\u001b[39m\u001b[38;5;124m'\u001b[39m: away_captain_last,\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfouls_home\u001b[39m\u001b[38;5;124m'\u001b[39m: fouls_home,\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfouls_away\u001b[39m\u001b[38;5;124m'\u001b[39m: fouls_away,\n\u001b[1;32m--> 100\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossession_home\u001b[39m\u001b[38;5;124m'\u001b[39m: possession_home,\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossession_away\u001b[39m\u001b[38;5;124m'\u001b[39m: possession_away,\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrosses_home\u001b[39m\u001b[38;5;124m'\u001b[39m: crosses_home,\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrosses_away\u001b[39m\u001b[38;5;124m'\u001b[39m: crosses_away,\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterceptions_home\u001b[39m\u001b[38;5;124m'\u001b[39m: interceptions_home,\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterceptions_away\u001b[39m\u001b[38;5;124m'\u001b[39m: interceptions_away,\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsides_home\u001b[39m\u001b[38;5;124m'\u001b[39m: offsides_home,\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsides_away\u001b[39m\u001b[38;5;124m'\u001b[39m: offsides_away,\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorners_home\u001b[39m\u001b[38;5;124m'\u001b[39m: corners_home,\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorners_away\u001b[39m\u001b[38;5;124m'\u001b[39m: corners_away,\n\u001b[0;32m    110\u001b[0m     }])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError accessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for Match ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'possession_home' is not defined"
     ]
    }
   ],
   "source": [
    "# this is still not handle\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Match URL and ID\n",
    "url = 'https://fbref.com/en/matches/b1544fc3/New-Mexico-United-Pittsburgh-Riverhounds-March-9-2024-USL-Championship'\n",
    "match_id = 1\n",
    "\n",
    "try:\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    webpage_content = response.text\n",
    "\n",
    "    # Parse the webpage using BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage_content, 'html.parser')\n",
    "\n",
    "    # Extract managers\n",
    "    manager_elements = soup.find_all('div', class_='datapoint')\n",
    "    managers = []\n",
    "    for element in manager_elements:\n",
    "        if \"Manager\" in element.get_text():\n",
    "            manager_name = element.get_text(strip=True).split(':')[-1].strip()\n",
    "            clean_name = manager_name.replace('\\xa0', ' ')\n",
    "            managers.append(clean_name)\n",
    "\n",
    "    if len(managers) >= 2:\n",
    "        home_manager_full = managers[0]\n",
    "        away_manager_full = managers[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both manager names on the page.\")\n",
    "\n",
    "    # Split managers into first and last names\n",
    "    home_manager_first, home_manager_last = home_manager_full.split(' ', 1)\n",
    "    away_manager_first, away_manager_last = away_manager_full.split(' ', 1)\n",
    "\n",
    "    # Extract captains\n",
    "    captains = []\n",
    "    for element in manager_elements:\n",
    "        if \"Captain\" in element.get_text():\n",
    "            captain_name = element.get_text(strip=True).split(':')[-1].strip()\n",
    "            clean_name = captain_name.replace('\\xa0', ' ')\n",
    "            captains.append(clean_name)\n",
    "\n",
    "    if len(captains) >= 2:\n",
    "        home_captain_full = captains[0]\n",
    "        away_captain_full = captains[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both captain names on the page.\")\n",
    "\n",
    "    # Split captains into first and last names\n",
    "    home_captain_first, home_captain_last = home_captain_full.split(' ', 1)\n",
    "    away_captain_first, away_captain_last = away_captain_full.split(' ', 1)\n",
    "\n",
    "     # Extract possession stats from the \"Team Stats\" table\n",
    "    possession_table = soup.find('h2', string=\"Team Stats\").find_next('table')\n",
    "    possession_values = possession_table.find_all('strong')\n",
    "\n",
    "    if len(possession_values) >= 2:\n",
    "        home_possession = possession_values[0].get_text(strip=True).replace('%', '')\n",
    "        away_possession = possession_values[1].get_text(strip=True).replace('%', '')\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both possession stats in the Team Stats table.\")\n",
    "\n",
    "    # Extract the stats from <div id=\"team_stats_extra\">\n",
    "    extra_stats = soup.find('div', id='team_stats_extra')\n",
    "    stat_labels = extra_stats.find_all('div', class_='th')\n",
    "    stat_values = extra_stats.find_all('div')\n",
    "\n",
    "    # Extract the values and assign them to the respective teams\n",
    "    fouls_home = stat_values[0].get_text(strip=True)\n",
    "    fouls_away = stat_values[2].get_text(strip=True)\n",
    "    \n",
    "    corners_home = stat_values[3].get_text(strip=True)\n",
    "    corners_away = stat_values[5].get_text(strip=True)\n",
    "    \n",
    "    crosses_home = stat_values[6].get_text(strip=True)\n",
    "    crosses_away = stat_values[8].get_text(strip=True)\n",
    "    \n",
    "    interceptions_home = stat_values[9].get_text(strip=True)\n",
    "    interceptions_away = stat_values[11].get_text(strip=True)\n",
    "    \n",
    "    offsides_home = stat_values[12].get_text(strip=True)\n",
    "    offsides_away = stat_values[14].get_text(strip=True)\n",
    "    \n",
    "       \n",
    "    # Create a DataFrame to store the match stats\n",
    "    match_stats = pd.DataFrame([{\n",
    "        'match_id': match_id,\n",
    "        'home_manager_first': home_manager_first,\n",
    "        'home_manager_last': home_manager_last,\n",
    "        'away_manager_first': away_manager_first,\n",
    "        'away_manager_last': away_manager_last,\n",
    "        'home_captain_first': home_captain_first,\n",
    "        'home_captain_last': home_captain_last,\n",
    "        'away_captain_first': away_captain_first,\n",
    "        'away_captain_last': away_captain_last,\n",
    "        'fouls_home': fouls_home,\n",
    "        'fouls_away': fouls_away,\n",
    "        'possession_home': possession_home,\n",
    "        'possession_away': possession_away,\n",
    "        'crosses_home': crosses_home,\n",
    "        'crosses_away': crosses_away,\n",
    "        'interceptions_home': interceptions_home,\n",
    "        'interceptions_away': interceptions_away,\n",
    "        'offsides_home': offsides_home,\n",
    "        'offsides_away': offsides_away,\n",
    "        'corners_home': corners_home,\n",
    "        'corners_away': corners_away,\n",
    "    }])\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error accessing {url} for Match ID {match_id}: {e}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Data extraction error for Match ID {match_id}: {ve}\")\n",
    "    \n",
    "match_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4714555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>home_manager_first</th>\n",
       "      <th>home_manager_last</th>\n",
       "      <th>away_manager_first</th>\n",
       "      <th>away_manager_last</th>\n",
       "      <th>home_captain_first</th>\n",
       "      <th>home_captain_last</th>\n",
       "      <th>away_captain_first</th>\n",
       "      <th>away_captain_last</th>\n",
       "      <th>home_possession</th>\n",
       "      <th>...</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_crosses</th>\n",
       "      <th>away_crosses</th>\n",
       "      <th>home_interceptions</th>\n",
       "      <th>away_interceptions</th>\n",
       "      <th>home_offsides</th>\n",
       "      <th>away_offsides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Quill</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Lilley</td>\n",
       "      <td>Kalen</td>\n",
       "      <td>Ryden</td>\n",
       "      <td>Danny</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id home_manager_first home_manager_last away_manager_first  \\\n",
       "0        1               Eric             Quill                Bob   \n",
       "\n",
       "  away_manager_last home_captain_first home_captain_last away_captain_first  \\\n",
       "0            Lilley              Kalen             Ryden              Danny   \n",
       "\n",
       "  away_captain_last home_possession  ... home_corners away_corners home_fouls  \\\n",
       "0           Griffin              66  ...         None         None       None   \n",
       "\n",
       "  away_fouls home_crosses away_crosses home_interceptions away_interceptions  \\\n",
       "0       None         None         None               None               None   \n",
       "\n",
       "  home_offsides away_offsides  \n",
       "0             4             2  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Match URL and ID\n",
    "url = 'https://fbref.com/en/matches/b1544fc3/New-Mexico-United-Pittsburgh-Riverhounds-March-9-2024-USL-Championship'\n",
    "match_id = 1\n",
    "\n",
    "# Assuming match_stats is already defined as an empty DataFrame or contains previous data\n",
    "# Initialize match_stats if it doesn't exist yet\n",
    "match_stats = pd.DataFrame(columns=[\n",
    "    'match_id', 'home_manager_first', 'home_manager_last', \n",
    "    'away_manager_first', 'away_manager_last', \n",
    "    'home_captain_first', 'home_captain_last', \n",
    "    'away_captain_first', 'away_captain_last', \n",
    "    'home_possession', 'away_possession', \n",
    "    'home_corners', 'away_corners', \n",
    "    'home_fouls', 'away_fouls', 'home_crosses', 'away_crosses', \n",
    "    'home_interceptions', 'away_interceptions', \n",
    "    'home_offsides', 'away_offsides'\n",
    "])\n",
    "\n",
    "try:\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    webpage_content = response.text\n",
    "\n",
    "    # Parse the webpage using BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage_content, 'html.parser')\n",
    "\n",
    "    # Extract managers (same logic as before)\n",
    "    manager_elements = soup.find_all('div', class_='datapoint')\n",
    "    managers = []\n",
    "    for element in manager_elements:\n",
    "        if \"Manager\" in element.get_text():\n",
    "            manager_name = element.get_text(strip=True).split(':')[-1].strip()\n",
    "            clean_name = manager_name.replace('\\xa0', ' ')\n",
    "            managers.append(clean_name)\n",
    "\n",
    "    if len(managers) >= 2:\n",
    "        home_manager_full = managers[0]\n",
    "        away_manager_full = managers[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both manager names on the page.\")\n",
    "\n",
    "    # Split managers into first and last names\n",
    "    home_manager_first, home_manager_last = home_manager_full.split(' ', 1)\n",
    "    away_manager_first, away_manager_last = away_manager_full.split(' ', 1)\n",
    "\n",
    "    # Extract captains (same logic as before)\n",
    "    captains = []\n",
    "    for element in manager_elements:\n",
    "        if \"Captain\" in element.get_text():\n",
    "            captain_name = element.get_text(strip=True).split(':')[-1].strip()\n",
    "            clean_name = captain_name.replace('\\xa0', ' ')\n",
    "            captains.append(clean_name)\n",
    "\n",
    "    if len(captains) >= 2:\n",
    "        home_captain_full = captains[0]\n",
    "        away_captain_full = captains[1]\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both captain names on the page.\")\n",
    "\n",
    "    # Split captains into first and last names\n",
    "    home_captain_first, home_captain_last = home_captain_full.split(' ', 1)\n",
    "    away_captain_first, away_captain_last = away_captain_full.split(' ', 1)\n",
    "\n",
    "    # Extract possession stats from the \"Team Stats\" table\n",
    "    possession_table = soup.find('h2', string=\"Team Stats\").find_next('table')\n",
    "    possession_values = possession_table.find_all('strong')\n",
    "\n",
    "    if len(possession_values) >= 2:\n",
    "        home_possession = possession_values[0].get_text(strip=True).replace('%', '')\n",
    "        away_possession = possession_values[1].get_text(strip=True).replace('%', '')\n",
    "    else:\n",
    "        raise ValueError(\"Unable to locate both possession stats in the Team Stats table.\")\n",
    "\n",
    "    # Extract the stats from <div id=\"team_stats_extra\"> (Corners, Fouls, Crosses, etc.)\n",
    "    extra_stats = soup.find('div', id='team_stats_extra')\n",
    "    \n",
    "    # Get all stats rows\n",
    "    stat_rows = extra_stats.find_all('div', class_=lambda class_name: class_name != 'th')\n",
    "    \n",
    "    # Initialize the values to None in case extraction fails\n",
    "    fouls_home, fouls_away = None, None\n",
    "    corners_home, corners_away = None, None\n",
    "    crosses_home, crosses_away = None, None\n",
    "    interceptions_home, interceptions_away = None, None\n",
    "    offsides_home, offsides_away = None, None\n",
    "    \n",
    "    # Loop through the rows and extract the relevant values\n",
    "    for i in range(0, len(stat_rows), 3):\n",
    "        stat_value_home = stat_rows[i].get_text(strip=True)\n",
    "        stat_name = stat_rows[i + 1].get_text(strip=True)\n",
    "        stat_value_away = stat_rows[i + 2].get_text(strip=True)\n",
    "        \n",
    "        # Extract fouls\n",
    "        if stat_name == 'Fouls':\n",
    "            fouls_home = stat_value_home\n",
    "            fouls_away = stat_value_away\n",
    "        \n",
    "        # Extract corners\n",
    "        if stat_name == 'Corners':\n",
    "            corners_home = stat_value_home\n",
    "            corners_away = stat_value_away\n",
    "        \n",
    "        # Extract crosses\n",
    "        if stat_name == 'Crosses':\n",
    "            crosses_home = stat_value_home\n",
    "            crosses_away = stat_value_away\n",
    "        \n",
    "        # Extract interceptions\n",
    "        if stat_name == 'Interceptions':\n",
    "            interceptions_home = stat_value_home\n",
    "            interceptions_away = stat_value_away\n",
    "        \n",
    "        # Extract offsides\n",
    "        if stat_name == 'Offsides':\n",
    "            offsides_home = stat_value_home\n",
    "            offsides_away = stat_value_away\n",
    "\n",
    "    # Create a new row with the extracted data\n",
    "    new_row = {\n",
    "        'match_id': match_id,\n",
    "        'home_manager_first': home_manager_first,\n",
    "        'home_manager_last': home_manager_last,\n",
    "        'away_manager_first': away_manager_first,\n",
    "        'away_manager_last': away_manager_last,\n",
    "        'home_captain_first': home_captain_first,\n",
    "        'home_captain_last': home_captain_last,\n",
    "        'away_captain_first': away_captain_first,\n",
    "        'away_captain_last': away_captain_last,\n",
    "        'home_possession': home_possession,\n",
    "        'away_possession': away_possession,\n",
    "        'home_corners': corners_home,\n",
    "        'away_corners': corners_away,\n",
    "        'home_fouls': fouls_home,\n",
    "        'away_fouls': fouls_away,\n",
    "        'home_crosses': crosses_home,\n",
    "        'away_crosses': crosses_away,\n",
    "        'home_interceptions': interceptions_home,\n",
    "        'away_interceptions': interceptions_away,\n",
    "        'home_offsides': offsides_home,\n",
    "        'away_offsides': offsides_away\n",
    "    }\n",
    "    \n",
    "    # Use pd.concat() to append the new row to match_stats\n",
    "    new_row_df = pd.DataFrame([new_row])  # Convert the dictionary to a DataFrame\n",
    "    match_stats = pd.concat([match_stats, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error accessing {url} for Match ID {match_id}: {e}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Data extraction error for Match ID {match_id}: {ve}\")\n",
    "\n",
    "match_stats.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5064ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
